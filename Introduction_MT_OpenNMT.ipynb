{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwYtIqx7VMjL"
      },
      "source": [
        "# Introduction à MT avec OpenNMT.\n",
        "\n",
        "![OPENNMT](https://avatars.githubusercontent.com/u/23035727?s=200&v=4)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobotsMali-AI/rmai/blob/master/Introduction_MT_OpenNMT.ipynb)\n",
        "\n",
        "Présenté par:\n",
        "\n",
        "- Sebastien Diarra, Michael Leventhal\n",
        "\n",
        "Procédure :\n",
        "\n",
        "- IndabaX Mali 2022\n",
        "\n",
        "## Agenda\n",
        "- À savoir\n",
        "- Introduction\n",
        "- Prérequis\n",
        "- Configuration de l'Environnement\n",
        "- Préparation des données\n",
        "- Architecture du modèle\n",
        "- Entraînement\n",
        "- Essai & Évaluation des performances [BLEU, Tensorboard]\n",
        "- Questions et Réponses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHNJcDVFQ1qG"
      },
      "source": [
        "\n",
        "## Buts et objectifs\n",
        "- Pour que vous compreniez le MT. Pipeline\n",
        "- Apprenez à configurer l'environnement OpenNMT\n",
        "- Pour vous intéresser à notre initiative Bayɛlɛmabaga & MT pour les langues locales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKYLP6Hbjh4v"
      },
      "source": [
        "**REMARQUES IMPORTANTES** :\n",
        "\n",
        "- Cette pratique est destinée à ceux qui n'ont aucune expérience en MT ou ML d'ailleurs.\n",
        "- La pratique est davantage axée sur l'action plutôt que sur le récit.\n",
        "- J'espère que vous quitterez cette session avec un désir de contribuer au travail de MT pour le Mali.\n",
        "- Vous n'avez pas besoin d'être un expert pour contribuer. Vous pouvez contribuer Data !\n",
        "\n",
        "*NB* : Joignez-vous à quelqu'un avec un ordinateur si vous n'avez pas apporté le vôtre."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHKbVDEBQ1qI"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Dans cette pratique, nous découvrirons OpenNMT et comment former un modèle de traduction automatique bilingue pour le bambara - français. Ceci est un tutoriel d'introduction pour se mouiller les pieds. Une approche pratique est fortement recommandée, tous les participants sont encouragés à suivre. Le code source de cet atelier peut être exécuté via Colab à l'URL suivante :\n",
        "\n",
        "[Notebook](https://colab.research.google.com/github/RobotsMali-AI/rmai/blob/master/Fr_Introduction_MT_OpenNMT.ipynb)\n",
        "\n",
        "\n",
        "### [OpenNMT](https://opennmt.net/)\n",
        "\n",
        "\"OpenNMT - est un écosystème open source pour la traduction automatique neuronale et l'apprentissage des séquences neuronales\"\n",
        "\n",
        "C'est un framework, ou toolkit, qui permet d'entrainer un modèle de langage.\n",
        "\n",
        "OpenNMT est pour :\n",
        "- Débutants\n",
        "- Amateur\n",
        "- Experts\n",
        "\n",
        "### MT (Traduction Automatique)\n",
        "\n",
        "Processus automatisé de traduction d'une langue à une autre par machine sans intervention humaine. La traduction est généralement effectuée par un programme informatique. Il existe différents types de MT :\n",
        "\n",
        "- MT basée sur des règles : règles de grammaire et de langue utilisées comme base pour un logiciel pour effectuer la traduction.\n",
        "\n",
        "![RULE-IMAGE](https://i.ibb.co/7XbQV0H/grammar-rules.png)\n",
        "\n",
        "- SMT : MT statistique : apprentissage basé sur la distribution de probabilité.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img alt=\"SMT\" width=\"300\"; height=\"250\" src=\"https://www.researchgate.net/profile/Andy-Way/publication/220418877/figure/fig5/AS:669019598245898@1536518110475/A-Statistical-Machine-Translation-System-adapted-from-Figure-1-in-Brown-et-al-13.png\" />\n",
        "\n",
        "<sub>Courtesy of: https://www.researchgate.net/publication/220418877_Hybrid_data-driven_models_of_machine_translation</sub>\n",
        "</div>\n",
        "\n",
        "- NMT : Neural Machine Translation : Apprentissage basé sur les réseaux de neurones artificiels.\n",
        "\n",
        "**NMT : c'est ce qui nous intéresse dans cet atelier**\n",
        "\n",
        "### NMT\n",
        "\n",
        "Est-ce l'utilisation de techniques d'apprentissage en profondeur (réseaux de neurones) pour former un modèle de traduction. Cette approche est devenue l'approche dominante pour faire de la traduction automatique. NMT s'est avéré très efficace dans la traduction automatique ces dernières années.\n",
        "\n",
        "<div>\n",
        "<img width=\"300\" height=\"250\" src=\"https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork-WHITEBG.png\">\n",
        "</div>\n",
        "\n",
        "OpenNMT -- nous aide à expérimenter rapidement la NMT, ainsi qu'à créer des systèmes/solutions de MT en moins de temps.\n",
        "\n",
        "NMT englobe les deux autres approches dans une certaine mesure.\n",
        "\n",
        "**NB** : ***Venez à l'événement PNL samedi, pour apprendre ces concepts en détail.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc_4xo9vaYN4"
      },
      "source": [
        "## Prérequis\n",
        "- Compréhension de la CLI Unix (aide)\n",
        "- Compréhension de Python (JupyterNB)\n",
        "- Les concepts de base de ML (tels que Pipeline, Models, NN) aident mais ne sont pas obligatoires\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3l7XwllQ1qL"
      },
      "source": [
        "## Configuration de l'Environnement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcysJBiGQ1qM"
      },
      "source": [
        "### Paquets\n",
        "\n",
        "- `OpenNMT-py` : paquet opennmt principal (version pytorch)\n",
        "- `rmaipkg` : Package pour les ensembles de données et les modèles de RobotsMaliAI (Later)\n",
        "- `Daba` (non requis) : une version modifiée de [daba](https://github.com/maslinych/daba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpEX2wSJQ1qN"
      },
      "outputs": [],
      "source": [
        "%pip install OpenNMT-py subword_nmt sentencepiece # Main OpenNMT Package (No Need for subword_nmt sentencepiece)\n",
        "%pip install --no-cache-dir https://github.com/RobotsMali-AI/rmai/releases/download/0.0.3/rmaipkg-0.0.3.tar.gz # RobotsMaliAI's Datasets and Models\n",
        "%pip install -U https://github.com/s7d11/daba/releases/download/v0.0.1-alpha/daba-0.9.2.tar.gz # Non-UI Version of Daba\n",
        "%pip install sacrebleu # Redundant comes with OpenNMT-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvsF2lYkQ1qR"
      },
      "source": [
        "### Configuration de l'espace de travail (Google Colab)\n",
        "\n",
        "- Qu'est-ce que Colab ?\n",
        "\n",
        "- Local vs Google Drive\n",
        "    - Experimentation vs Persistence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYni0OdzQ1qS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "# TODO: validate that user works on Colab\n",
        "\n",
        "# Select your environment\n",
        "WORK_ENV = 0 # 0=Local 1=Drive\n",
        "\n",
        "CWD = os.getcwd()\n",
        "WORK_DIR_Lo = CWD+\"/onmt\"#\"/content/onmt\"\n",
        "\n",
        "if(WORK_ENV):\n",
        "    if os.path.exists(\"/content\"):\n",
        "        from google.colab import drive\n",
        "        WORK_DIR_Dr = \"/content/drive/MyDrive/onmt\"\n",
        "        drive.mount('/content/drive') # Mounting your Google drive\n",
        "    else:\n",
        "        print(\"Colab not detected. Reverting to local environment\")\n",
        "        WORK_DIR_Dr = WORK_DIR_Lo\n",
        "\n",
        "WORK_DIR = WORK_DIR_Dr if WORK_ENV else WORK_DIR_Lo\n",
        "DATA_DIR = f\"{WORK_DIR}/data\"\n",
        "\n",
        "if(not os.path.exists(WORK_DIR)):\n",
        "    !mkdir -p $DATA_DIR\n",
        "    print(f\"Environment Created: {WORK_DIR}\")\n",
        "else:\n",
        "    print(\"Environment already exists...\")\n",
        "\n",
        "os.chdir(WORK_DIR) # Naviting to Work-environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54CbNv34Q1qT"
      },
      "source": [
        "### Activer le GPU\n",
        "\n",
        "- Édition > Paramètres du bloc-notes > GPU > Enregistrer\n",
        "- Exécution > GPU\n",
        "\n",
        "\n",
        "**IMPORTANT** : Gardez le GPU détaché jusqu'à ce que vous fassiez quelque chose qui nécessite des GPU (c'est-à-dire de l'entrainement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUmORoIBbyTi"
      },
      "outputs": [],
      "source": [
        "# GPU's information\n",
        "\n",
        "!nvidia-smi "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSZVdDz8Q1qU"
      },
      "source": [
        "## Préparation des données\n",
        "\n",
        "`rmaipkg` a des textes Bambara parallèles que nous utiliserons pour cette étape. Vous échangez facilement cela avec votre source de données.\n",
        "\n",
        "\n",
        "Sachez à l'avance : ***Le texte n'est pas entièrement nettoyé si vous rencontrez des problèmes, il est préférable de générer un échantillon différent***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pEFFe89CPfp"
      },
      "outputs": [],
      "source": [
        "# Import the 'parralel' module from rmaipkg\n",
        "from rmai.datasets.text import parallel\n",
        "\n",
        "texts = parallel.get_text(max_len=10000, randomize=True) # Load texts in memory\n",
        "\n",
        "# Show first 10 lines\n",
        "print(texts[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSJ3G6z5Q1qV"
      },
      "source": [
        "- `parallel` : module pour les textes parallèles de RobotsMali\n",
        "- `parallèle.get_text` :\n",
        "    - retourne `max_len` nombre de lignes\n",
        "    - `randomize` lorsqu'il est défini, mélange les textes. Bon pour générer un ordre différent pour les textes à chaque exécution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYJ6O1jRQ1qW"
      },
      "outputs": [],
      "source": [
        "\n",
        "train, valid = parallel.random_split(texts, 80) # Split Data into training and validation 80/20\n",
        "\n",
        "print(\n",
        "    \"Splitted correctly: \", \n",
        "    len(train)+len(valid) == len(texts)) # Sanity Check\n",
        " \n",
        "\"\"\"\n",
        "TASK I: Create the following variables containing unique language for each set\n",
        "- trainbam: train set bambara\n",
        "- trainfra: train set francais\n",
        "- validbam: valid set bambara\n",
        "- validfra: valid set francais\n",
        "\"\"\"\n",
        "\n",
        "# CODE HERE (Discuss in pseudo code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ite-dBrpQ1qX"
      },
      "source": [
        "- `parallel.random_split` : divise l'objet texte en ratios pour l'entraînement et la validation, il renvoie un type de tuple.\n",
        "    - Le premier argument est les \"textes\"\n",
        "    - Le deuxième argument est le taux auquel c'est divisé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zZRnj5XCQ1qX"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Task I - Solution\n",
        "x_extractor = lambda x, dset: [i[x] for i in dset]\n",
        "\n",
        "trainbam = x_extractor(0, train)\n",
        "trainfra = x_extractor(1, train)\n",
        "validbam = x_extractor(0, valid)\n",
        "validfra = x_extractor(1, valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs46PTx_Q1qY"
      },
      "source": [
        "- `x_extractor` est une fonction lambda pour la tâche de séparer les valeurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHLvrGbb7psQ"
      },
      "outputs": [],
      "source": [
        "# Optional Work - Further Cleaning the Data\n",
        "\n",
        "import string\n",
        "\n",
        "def clean_lines(lines):\n",
        "  nlines = []\n",
        "  for i in lines:\n",
        "    for j in string.punctuation + \"«»\":\n",
        "      if(not j in r\"!.:?()[]\"):\n",
        "        i = i.replace(j, \" \")\n",
        "    nlines.append(i)\n",
        "  return \" \".join(\"\".join(nlines).strip().split())\n",
        "\n",
        "trainbam = [clean_lines(i) for i in trainbam]\n",
        "trainfra = [clean_lines(i) for i in trainfra]\n",
        "validbam = [clean_lines(i) for i in validbam]\n",
        "validfra = [clean_lines(i) for i in validfra]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIH7wZMTQ1qZ"
      },
      "source": [
        "- Écrivons maintenant nos données dans des fichiers réels sur le système. `rmaipkg` a une méthode appelée `write_to` qui le fait pour nous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UqyLq4n7kYl"
      },
      "outputs": [],
      "source": [
        "parallel.write_to(lines=trainbam, name=\"src-train\", path=DATA_DIR)\n",
        "parallel.write_to(lines=trainfra, name=\"tgt-train\", path=DATA_DIR)\n",
        "parallel.write_to(lines=validbam, name=\"src-val\", path=DATA_DIR)\n",
        "parallel.write_to(lines=validfra, name=\"tgt-val\", path=DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQIYPHHyQ1qa"
      },
      "source": [
        "Maintenant que nous avons écrit nos données et que nous avons un ensemble de données, adaptons-le maintenant à la traduction automatique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M6IYseaQ1qa"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_name = \"bam2fr\" # Name you are giving to your model\n",
        "config_name = f\"{WORK_DIR}/cool_config.yaml\"\n",
        "\n",
        "config = f\"\"\"\n",
        "\n",
        "# IndabaX - Mali 2022 (Configuration)\n",
        "\n",
        "save_data: {model_name}/run/{model_name}\n",
        "\n",
        "overwrite: True # Toggle this for rewritting\n",
        "\n",
        "data:  \n",
        "    robotsmali:\n",
        "        path_src: data/src-train.txt # DataPath\n",
        "        path_tgt: data/tgt-train.txt\n",
        "        transforms: []\n",
        "        weight: 1\n",
        "    valid:\n",
        "        path_src: data/src-val.txt\n",
        "        path_tgt: data/tgt-val.txt\n",
        "        transforms: []\n",
        "        weight: 1\n",
        "\n",
        "src_seq_length: 250\n",
        "tgt_seq_length: 250\n",
        "\n",
        "src_vocab: {model_name}/run/{model_name}.vocab.src.txt\n",
        "tgt_vocab: {model_name}/run/{model_name}.vocab.tgt.txt\n",
        "skip_empty_level: silent\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write config file\n",
        "with open(config_name, \"w\") as fp:\n",
        "    fp.write(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AkOmTviQ1qb"
      },
      "source": [
        "Ici, nous avons créé un fichier de configuration `cool_config.yaml` contenant des informations générales sur le jeu de données. Qu'avons-nous fait:\n",
        "\n",
        "- Nous avons attribué le nom de notre modèle à une variable\n",
        "- Générez un fichier de configuration avec quelques détails de base tels que :\n",
        "    - où se trouvent les données\n",
        "    - où générer les fichiers de vocabulaire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-riq5HkO3Kl"
      },
      "outputs": [],
      "source": [
        "# OpenNMT Building the vocabulary\n",
        "\n",
        "!onmt_build_vocab -c $config_name -n_sample -1 --dump_samples # -1 full corpus, bpe, sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe34hfPxQ1qc"
      },
      "source": [
        "La commande `onmt_build_vocab` construit le vocabulaire nécessaire à la formation. Ici, nous l'avons appelé avec trois paramètres\n",
        "\n",
        "- `-c config_file` : chemin du fichier de configuration à utiliser pour le processus de création de vocabulaire\n",
        "\n",
        "- `-n_sample -1` : la construction d'un vocabulaire à l'aide du corpus complet peut remplacer **-1** par n'importe quel nombre, lorsque l'argument est omis, sa valeur par défaut est 5000.\n",
        "\n",
        "- `-- dump_sampes` : (argument facultatif) Écrire des échantillons lors de la construction du vocabulaire, trouvés dans `model_name/run/model_name`\n",
        "\n",
        "Nous n'avons pas besoin de construire un vocabulaire en utilisant le `onmt_build_vocab`, nous pouvons le construire nous-mêmes souvent cela est nécessaire, `tokenization` varie selon la langue, chaque langue a ses caractéristiques uniques. Un exemple de ceci est montré ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYamw9WKQ1qc"
      },
      "outputs": [],
      "source": [
        "# Custom Tokenization (rm-daba-tokenizer) \n",
        "# - Shown as example, CELL can be skipped\n",
        "\n",
        "from rmai.utils import daba\n",
        "\n",
        "dabautil = daba.DabaUtils()\n",
        "dabautil.tokenize_line(trainbam+validbam)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16UMoYNuQ1qc"
      },
      "source": [
        "[`Daba`](https://github.com/maslinych/daba) est un outil incroyable développé par des linguistes de l'INALCO. Daba est une ceinture à outils pour les linguistes, et par conséquent pour nous, les gens des sciences informatiques qui cherchons à travailler avec la langue bambara.\n",
        "\n",
        "- Si vous cherchez à travailler avec Bambara, nous vous le recommandons fortement.\n",
        "\n",
        "\n",
        "(Retour à OpenNMT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNxx3TUCQ1qd"
      },
      "source": [
        "### Entraînement\n",
        "\n",
        "\n",
        "#### Architecture d'un modèle\n",
        "\n",
        "Nous \"concevons\" le modèle à travers la configuration que nous avons générée précédemment. Dans la cellule de code ci-dessous, nous écrivons comment nous nous attendons à ce que notre modèle soit.\n",
        "\n",
        "*Bien que le fichier de configuration puisse être mis à jour et ajusté.* Nous limiterons notre modification à quelques options, car nous n'avons pas assez de temps pour en discuter.\n",
        "\n",
        "Vous pouvez appeler cette configuration comme ingrédients de la sorcière.\n",
        "\n",
        "- save_model : est le chemin dans lequel le point de contrôle de notre modèle est enregistré.\n",
        "- save_checkpoint_steps : X, à chaque étape X de l'entraînement, un point de contrôle est enregistré.\n",
        "- train_steps : Nombre d'étapes d'entraînement\n",
        "- valid_steps : exécuter la validation, toutes les X étapes\n",
        "- warmup_step : étape permettant d'ajuster le taux d'apprentissage après le début de l'entraînement.\n",
        "- GPU : basculer si vous utilisez GPU ou CPU\n",
        "\n",
        "BTW : Il s'agit d'une architecture de modèle de transformateur (transformer).\n",
        "\n",
        "Inspiré de :\n",
        "- [https://github.com/OpenNMT/OpenNMT-py/blob/master/config/config-transformer-base-1GPU.yml](https://github.com/OpenNMT/OpenNMT-py/blob/master/config/config-transformer-base-1GPU.yml)\n",
        "- Travail effectué par [A. A. Tapo](https://github.com/israaar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJdJ145pQ1qd"
      },
      "outputs": [],
      "source": [
        "save_freq =  5 #100 # Checkpoint saving steps\n",
        "training_steps = 10 #500 # Number of steps for the training\n",
        "valid_steps = 2# 50 # Steps to validate training perfomance\n",
        "warmup_step = 3 #125 # Warmup 1/4th of training total\n",
        "GPU = 0 # 0: CPU or 1:GPU\n",
        "\n",
        "config += f\"\"\"\n",
        "\n",
        "# Training\n",
        "save_model: {model_name}/{model_name}\n",
        "save_checkpoint_steps: {save_freq}\n",
        "keep_checkpoint: 3 # Better for this activity\n",
        "seed: 1234\n",
        "train_steps: {training_steps}\n",
        "valid_steps: {valid_steps}\n",
        "warmup_steps: {warmup_step}\n",
        "report_every: {int(training_steps / 5)}\n",
        "external_evaluators: BLEU\n",
        "tensorboard: true\n",
        "tensorboard_log_dir: {model_name}/logs\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "word_vec_size: 256 # Word embedding size\n",
        "hidden_size: 256\n",
        "layers: 6\n",
        "transformer_ff: 1024\n",
        "heads: 4\n",
        "dropout: 0.3\n",
        "\n",
        "# HyperParams\n",
        "accum_count: 8\n",
        "optim: adam\n",
        "adam_beta1: 0.9\n",
        "adam_beta2: 0.998\n",
        "decay_method: noam\n",
        "learning_rate: 0.0004\n",
        "max_grad_norm: 0.0\n",
        "\n",
        "batch_size: 4096\n",
        "batch_type: tokens\n",
        "normalization: tokens\n",
        "label_smoothing: 0.2\n",
        "\n",
        "max_generator_batches: 0\n",
        "\n",
        "param_init: 0.0\n",
        "param_init_glorot: 'true'\n",
        "position_encoding: 'true'\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "if(GPU):\n",
        "    config += \"\"\"\n",
        "world_size: 1 # CPU\n",
        "gpu_ranks: [0] # Change to number of GPU if more than 1 GPU\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "TASK II - Rewrite the config with this new configuration\n",
        "\"\"\"\n",
        "\n",
        "# CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0rlimCoQSJuK"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "with open(config_name, \"w\") as fp:\n",
        "    fp.write(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_C_ZPwJQ1qf"
      },
      "source": [
        "- **NOW LET THE MAGIC BEGIN**\n",
        "\n",
        "Nous allons exécuter notre expérience, mais avant de lancer la commande d'entraînement, nous allons démarrer tensorboard. ***Tensorboard*** nous aide à visualiser ce qui se passe avec notre modèle de formation.\n",
        "\n",
        "**Important** : Si vous obtenez une erreur `403`. Activez Cookie / Autorisez le navigateur à afficher le Tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA-mTF1VVMkp"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir bam2fr/logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22JivmvFktz-"
      },
      "source": [
        "Le `onmt_train` prend le fichier de configuration comme argument. Espérons que si nous avons tout fait avant, la formation devrait commencer sans aucun problème. La durée de la formation dépend des étapes de formation, de la puissance de calcul et de data_size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooPXDOZ8PYYN"
      },
      "outputs": [],
      "source": [
        "!onmt_train -config $config_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOoCm4TOktz-"
      },
      "source": [
        "## Essai & Évaluation des performances [BLEU, Tensorboard]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uothZY8uLiZ"
      },
      "source": [
        "### Task 3\n",
        "- Créer son propre fichier de test (10 phrases)\n",
        "    - Créez un nouveau fichier with dans le répertoire `data` puis écrivez 10 lignes bambara sur le fichier.\n",
        "    - Créez un autre fichier dans le répertoire `data` puis écrivez la traduction française du fichier texte en bambara.\n",
        "\n",
        "### Vous pouvez utiliser notre kit de test si vous vous sentez paresseux ou sans inspiration\n",
        "\n",
        "- Copiez notre fichier de test à partir de [Repo](https://github.com/robotsmali-ai/rmai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R5-Mdf1zktz_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Test Set\n",
        "bamf = \"https://raw.githubusercontent.com/RobotsMali-AI/rmai/master/mbam.txt\"\n",
        "fraf = \"https://raw.githubusercontent.com/RobotsMali-AI/rmai/master/mfr.txt\"\n",
        "\n",
        "!wget {bamf} {fraf} -P data # Bam-Fra\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW-fthQWktz_"
      },
      "source": [
        "La commande `onmt_translate` est utilisée pour effectuer la traduction avec le modèle formé. Ici, nous utilisons cinq paramètres :\n",
        "- `model` : un fichier de point de contrôle de modèle\n",
        "- `src` : notre fichier de test la langue source\n",
        "- `output` : où nous voulons écrire les prédictions de notre modèle\n",
        "- `gpu` : nombre de GPU sur lesquels exécuter\n",
        "- `verbose` : affiche les scores par prédiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVmk4Q1DSqBa"
      },
      "outputs": [],
      "source": [
        "ckpt_step = 10\n",
        "tsrc = \"mbam.txt\" # Change this to your bambara test file\n",
        "\n",
        "selected_model_name = f\"{model_name}_step_{ckpt_step}.pt\"\n",
        "output = f\"{model_name}/pred_{model_name}_{ckpt_step}.txt\"\n",
        "\n",
        "!onmt_translate -model $model_name/$selected_model_name -src data/$tsrc -output $output # -gpu -1 -verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctkeXQrJkt0A"
      },
      "source": [
        "**Ta-da! Let's see how our model did, now.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYG9zMIYkt0A"
      },
      "outputs": [],
      "source": [
        "!cat $output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w03t08lLkt0A"
      },
      "source": [
        "Le score de Bleu `(BiLingual Evaluation Understudy)` est une mesure automatique pour évaluer la traduction automatique. C'est utile, car cela nous permet d'avoir une idée générale de la façon dont notre modèle fonctionne si nous travaillons avec un modèle plus grand et une taille de données plus grande.\n",
        "\n",
        "Dans notre cas, nous utiliserons notre propre traduction comme référence pour déterminer les performances de notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmwFxAjTQ1qh"
      },
      "outputs": [],
      "source": [
        "reference = \"data/mfr.txt\"\n",
        "\n",
        "!sacrebleu $reference -i $output -m bleu -b -w 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L23IDjKGkt0B"
      },
      "source": [
        "Prochaine étape : revenez en arrière et ajustez les paramètres pour votre propre personnalisation.\n",
        "\n",
        ">>> **Merci de nous avoir rejoint. Venez à l'événement N.L.P samedi pour en savoir plus sur NLP, ASR en détails.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vslfOYyiQ1qh"
      },
      "source": [
        "<div>\n",
        "\n",
        "<img width=\"250\" src=\"https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img/https://indabax.robotsmali.org/wp-content/uploads/2022/11/robotsmali.png\" />\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.2 ('indabax-ml-practivcals')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "062df52f2add3985dc8f7857aa357ac7d0bf80c221fd747fc356e78d6365606f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
