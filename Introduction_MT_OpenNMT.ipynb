{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwYtIqx7VMjL"
      },
      "source": [
        "# Introduction à MT avec OpenNMT.\n",
        "\n",
        "![OPENNMT](https://avatars.githubusercontent.com/u/23035727?s=200&v=4)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobotsMali-AI/rmai/blob/master/Introduction_MT_OpenNMT.ipynb)\n",
        "\n",
        "Présenté par:\n",
        "\n",
        "- Sebastien Diarra, Michael Leventhal\n",
        "\n",
        "Procédure :\n",
        "\n",
        "- IndabaX Mali 2022\n",
        "\n",
        "## Agenda\n",
        "- À savoir\n",
        "- Introduction\n",
        "- Prérequis\n",
        "- Configuration de l'Environnement\n",
        "- Préparation des données\n",
        "- Architecture du modèle\n",
        "- Entraînement\n",
        "- Essai & Évaluation des performances [BLEU, Tensorboard]\n",
        "- Questions et Réponses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHNJcDVFQ1qG"
      },
      "source": [
        "\n",
        "## Buts et objectifs\n",
        "- Pour que vous compreniez le MT. Pipeline\n",
        "- Apprenez à configurer l'environnement OpenNMT\n",
        "- Pour vous intéresser à notre initiative Bayɛlɛmabaga & MT pour les langues locales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKYLP6Hbjh4v"
      },
      "source": [
        "**REMARQUES IMPORTANTES** :\n",
        "\n",
        "- Cette pratique est destinée à ceux qui n'ont aucune expérience en MT ou ML d'ailleurs.\n",
        "- La pratique est davantage axée sur l'action plutôt que sur le récit.\n",
        "- J'espère que vous acheverez cette session avec un désir de contribuer au travail de MT pour le Mali.\n",
        "- Vous n'avez pas besoin d'être un expert pour contribuer. Vous pouvez contribuer Data !\n",
        "\n",
        "*NB* : Joignez-vous à quelqu'un avec un ordinateur si vous n'avez pas apporté le vôtre."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHKbVDEBQ1qI"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Dans cette pratique, nous découvrirons OpenNMT et comment entrainer un modèle de traduction automatique bilingue pour le bambara - français. Ceci est un tutoriel d'introduction qui vous permettra d'acquérir un peu d'expérience pratique. Une approche pratique est fortement recommandée, tous les participants sont encouragés à suivre. Le code source de cet atelier peut être exécuté via Colab à l'URL suivante :\n",
        "\n",
        "[https://github.com/robotsmali-ai/rmai/blob/master/Introduction_MT_OpenNMT](https://colab.research.google.com/github/RobotsMali-AI/rmai/blob/master/Fr_Introduction_MT_OpenNMT.ipynb)\n",
        "\n",
        "\n",
        "### [OpenNMT](https://opennmt.net/)\n",
        "\n",
        "\"OpenNMT - est un écosystème open source pour la traduction automatique neuronale et l'apprentissage des séquences neuronales\"\n",
        "\n",
        "C'est un framework, ou toolkit, qui permet d'entrainer un modèle de langage.\n",
        "\n",
        "OpenNMT est pour :\n",
        "- Débutants\n",
        "- Amateur\n",
        "- Experts\n",
        "\n",
        "### MT (Traduction Automatique)\n",
        "\n",
        "Processus automatisé de traduction d'une langue à une autre par machine sans intervention humaine. La traduction est généralement effectuée par un programme informatique. Il existe différents types de MT :\n",
        "\n",
        "- MT basée sur des règles : règles de grammaire et de langue utilisées comme base pour un logiciel pour effectuer la traduction.\n",
        "\n",
        "![RULE-IMAGE](https://i.ibb.co/7XbQV0H/grammar-rules.png)\n",
        "\n",
        "- SMT : MT statistique : apprentissage basé sur la distribution de probabilité.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img alt=\"SMT\" width=\"300\"; height=\"250\" src=\"https://www.researchgate.net/profile/Andy-Way/publication/220418877/figure/fig5/AS:669019598245898@1536518110475/A-Statistical-Machine-Translation-System-adapted-from-Figure-1-in-Brown-et-al-13.png\" />\n",
        "\n",
        "<sub>Courtesy of: https://www.researchgate.net/publication/220418877_Hybrid_data-driven_models_of_machine_translation</sub>\n",
        "</div>\n",
        "\n",
        "- NMT : Neural Machine Translation : Apprentissage basé sur les réseaux de neurones artificiels.\n",
        "\n",
        "**NMT : c'est ce qui nous intéresse dans cet atelier**\n",
        "\n",
        "### NMT\n",
        "\n",
        "Est l'utilisation de techniques d'apprentissage en profondeur (réseaux de neurones) pour entrainer un modèle de traduction. Cette approche est devenue l'approche dominante pour faire de la traduction automatique. NMT s'est avéré très efficace dans la traduction automatique ces dernières années.\n",
        "\n",
        "<div>\n",
        "<img width=\"300\" height=\"250\" src=\"https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork-WHITEBG.png\">\n",
        "</div>\n",
        "\n",
        "OpenNMT -- nous aide à expérimenter rapidement la NMT, ainsi qu'à créer des systèmes/solutions de MT en moins de temps.\n",
        "\n",
        "NMT englobe les deux autres approches dans une certaine mesure.\n",
        "\n",
        "**NB** : ***Assistez à l'atelier NLP le samedi pour apprendre ces concepts en détail.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc_4xo9vaYN4"
      },
      "source": [
        "## Prérequis\n",
        "- Compréhension de la CLI Unix (aide)\n",
        "- Compréhension de Python (JupyterNB)\n",
        "- Les concepts de base de ML (tels que Pipeline, Models, NN) aident mais ne sont pas obligatoires\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3l7XwllQ1qL"
      },
      "source": [
        "## Configuration de l'Environnement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcysJBiGQ1qM"
      },
      "source": [
        "### Paquets (Modules)\n",
        "\n",
        "- `OpenNMT-py` : paquet opennmt principal (version pytorch)\n",
        "- `rmaipkg` : Package pour les ensembles de données et les modèles de RobotsMaliAI (Later)\n",
        "- `Daba` (non requis) : une version modifiée de [daba](https://github.com/maslinych/daba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpEX2wSJQ1qN"
      },
      "outputs": [],
      "source": [
        "%pip install OpenNMT-py subword_nmt sentencepiece # Main OpenNMT Package (No Need for subword_nmt sentencepiece)\n",
        "%pip install --no-cache-dir https://github.com/RobotsMali-AI/rmai/releases/download/0.0.4/rmaipkg-0.0.4.tar.gz # RobotsMaliAI's Datasets and Models\n",
        "%pip install -U https://github.com/s7d11/daba/releases/download/v0.0.1-alpha/daba-0.9.2.tar.gz # Non-UI Version of Daba\n",
        "%pip install sacrebleu # Redundant comes with OpenNMT-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvsF2lYkQ1qR"
      },
      "source": [
        "### Configuration de l'espace de travail (Google Colab)\n",
        "\n",
        "- Qu'est-ce que Colab ?\n",
        "\n",
        "- Local vs Google Drive\n",
        "    - Experimentation vs Persistence de Données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYni0OdzQ1qS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "# TODO: validate that user works on Colab\n",
        "\n",
        "# Select your environment\n",
        "WORK_ENV = 0 # 0=Local 1=Drive\n",
        "\n",
        "CWD = os.getcwd()\n",
        "WORK_DIR_Lo = CWD+\"/onmt\" if not os.path.exists(\"/content\") else \"/content/onmt\" #\"/content/onmt\"\n",
        "\n",
        "if(WORK_ENV):\n",
        "    if os.path.exists(\"/content\"):\n",
        "        from google.colab import drive\n",
        "        WORK_DIR_Dr = \"/content/drive/MyDrive/onmt\"\n",
        "        drive.mount('/content/drive') # Mounting your Google drive\n",
        "    else:\n",
        "        print(\"Colab not detected. Reverting to local environment\")\n",
        "        WORK_DIR_Dr = WORK_DIR_Lo\n",
        "\n",
        "WORK_DIR = WORK_DIR_Dr if WORK_ENV else WORK_DIR_Lo\n",
        "DATA_DIR = f\"{WORK_DIR}/data\"\n",
        "\n",
        "if(not os.path.exists(WORK_DIR)):\n",
        "    !mkdir -p $DATA_DIR\n",
        "    print(f\"Environment Created: {WORK_DIR}\")\n",
        "else:\n",
        "    print(\"Environment already exists...\")\n",
        "\n",
        "os.chdir(WORK_DIR) # Navigating to Work-environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54CbNv34Q1qT"
      },
      "source": [
        "### Activer le GPU (uniquement Colab)\n",
        "\n",
        "- Édition > Paramètres du notebook > GPU > Enregistrer\n",
        "- Exécution > GPU\n",
        "\n",
        "\n",
        "**IMPORTANT** : Gardez le GPU détaché jusqu'à ce que vous fassiez quelque chose qui nécessite des GPU (c'est-à-dire de l'entrainement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUmORoIBbyTi"
      },
      "outputs": [],
      "source": [
        "# GPU's information\n",
        "\n",
        "!nvidia-smi "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSZVdDz8Q1qU"
      },
      "source": [
        "## Préparation des données\n",
        "\n",
        "`rmaipkg` a des textes Bambara-Français parallèles que nous utiliserons pour cette tutoriels. Nous pouvons facilement integrer cela en tant que source de données.\n",
        "\n",
        "Sachez à l'avance : ***Le texte n'est pas entièrement nettoyé si vous rencontrez des problèmes, il est préférable de générer un échantillon différent***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSJ3G6z5Q1qV"
      },
      "source": [
        "- `parallel` : module pour les textes parallèles de RobotsMali\n",
        "- `parallel.get_text` :\n",
        "    - retourne `max_len` nombre de lignes\n",
        "    - `randomize` lorsqu'il est défini, mélange les textes. Bon pour générer un ordre différent pour les textes à chaque exécution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pEFFe89CPfp"
      },
      "outputs": [],
      "source": [
        "# Import the 'parallel' module from rmaipkg\n",
        "from rmai.datasets.text import parallel\n",
        "\n",
        "texts = parallel.get_text(\n",
        "    max_len=50000, randomize=True) # Load texts in memory\n",
        "\n",
        "# Show first 10 lines\n",
        "print(texts[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ite-dBrpQ1qX"
      },
      "source": [
        "- `parallel.random_split` : divise l'objet texte en ratios pour l'apprentissage et la validation de l'apprentissage, il renvoie un type de tuple.\n",
        "    - Le premier argument est les \"textes\"\n",
        "    - Le deuxième argument est le taux auquel c'est divisé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUo8oEkHl5pv"
      },
      "outputs": [],
      "source": [
        "train, valid = parallel.random_split(texts, 90) # Split Data into training and validation 80/20\n",
        "\n",
        "print(\n",
        "    \"Split correctly: \", \n",
        "    len(train)+len(valid) == len(texts)) # Sanity Chec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKhjZ5lHl5pw"
      },
      "source": [
        "*Tâche 1* Votre tâche ici est de créer les variables suivantes. Le contenu associé avec chaque variable sera les textes d'apprentissage ou de validation dans chaque langue.\n",
        "\n",
        "Astuce : Les textes sont dans les tableaux de tuples train et valid, le bambara précède le français dans chaque tuple.\n",
        "\n",
        "Si votre Python n'est pas encore à l'hauteur, vous trouverez la solution dans la cellule ci-dessous, vous pouvez l'exécuter directement.\n",
        "\n",
        "Les variables à créer sont :\n",
        "- trainbam: train set bambara\n",
        "- trainfra: train set francais\n",
        "- validbam: valid set bambara\n",
        "- validfra: valid set francais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYJ6O1jRQ1qW"
      },
      "outputs": [],
      "source": [
        "# CODE ou PSEUDOCODE ICI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zZRnj5XCQ1qX"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Task I - Solution\n",
        "x_extractor = lambda x, dset: [i[x] for i in dset]\n",
        "\n",
        "trainbam = x_extractor(0, train)\n",
        "trainfra = x_extractor(1, train)\n",
        "validbam = x_extractor(0, valid)\n",
        "validfra = x_extractor(1, valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs46PTx_Q1qY"
      },
      "source": [
        "- `x_extractor` est une fonction lambda pour la tâche de séparer les valeurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHLvrGbb7psQ"
      },
      "outputs": [],
      "source": [
        "# Pour améliorer les résultats - éliminer les caractères superflues des textes\n",
        "\n",
        "import string\n",
        "\n",
        "def clean_lines(lines):\n",
        "  nlines = []\n",
        "  for i in lines:\n",
        "    for j in string.punctuation + \"«»\":\n",
        "      if(not j in r\"!.:?()[]\"):\n",
        "        i = i.replace(j, \" \")\n",
        "    nlines.append(i)\n",
        "  return \" \".join(\"\".join(nlines).strip().split())\n",
        "\n",
        "trainbam = [clean_lines(i) for i in trainbam]\n",
        "trainfra = [clean_lines(i) for i in trainfra]\n",
        "validbam = [clean_lines(i) for i in validbam]\n",
        "validfra = [clean_lines(i) for i in validfra]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIH7wZMTQ1qZ"
      },
      "source": [
        "- Écrivons maintenant nos données dans des fichiers réels sur le système. `rmaipkg` a une méthode appelée `write_to` qui le fait pour nous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UqyLq4n7kYl"
      },
      "outputs": [],
      "source": [
        "parallel.write_to(lines=trainbam, name=\"src-train\", path=DATA_DIR)\n",
        "parallel.write_to(lines=trainfra, name=\"tgt-train\", path=DATA_DIR)\n",
        "parallel.write_to(lines=validbam, name=\"src-val\", path=DATA_DIR)\n",
        "parallel.write_to(lines=validfra, name=\"tgt-val\", path=DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQIYPHHyQ1qa"
      },
      "source": [
        "Maintenant que nous avons écrit nos données et que nous avons un ensemble de données, écrivons les informations afin que le modèle puisse l'utiliser pour l'apprentissage et la validation (configuration)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M6IYseaQ1qa"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_name = \"bam2fr\" # Nom de notre modèle\n",
        "config_name = f\"{WORK_DIR}/cool_config.yaml\"\n",
        "\n",
        "config = f\"\"\"\n",
        "\n",
        "# IndabaX - Mali 2022 (Configuration)\n",
        "\n",
        "save_data: {model_name}/run/{model_name}\n",
        "\n",
        "overwrite: True # Toggle this for rewritting\n",
        "\n",
        "data:  \n",
        "    robotsmali:\n",
        "        path_src: data/src-train.txt # DataPath\n",
        "        path_tgt: data/tgt-train.txt\n",
        "        transforms: []\n",
        "        weight: 1\n",
        "    valid:\n",
        "        path_src: data/src-val.txt\n",
        "        path_tgt: data/tgt-val.txt\n",
        "        transforms: []\n",
        "        weight: 1\n",
        "\n",
        "# src_seq_length: 250\n",
        "# tgt_seq_length: 250\n",
        "\n",
        "src_vocab: {model_name}/run/{model_name}.vocab.src.txt\n",
        "tgt_vocab: {model_name}/run/{model_name}.vocab.tgt.txt\n",
        "# skip_empty_level: silent\n",
        "\n",
        "tensorboard: true\n",
        "tensorboard_log_dir: logs\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Write config file\n",
        "with open(config_name, \"w\") as fp:\n",
        "    fp.write(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AkOmTviQ1qb"
      },
      "source": [
        "Ici, nous avons créé un fichier de configuration `cool_config.yaml` contenant des informations générales sur le jeu de données. Qu'avons-nous fait ? :\n",
        "\n",
        "- Nous avons attribué le nom de notre modèle à une variable\n",
        "- Générez un fichier de configuration avec quelques détails de base tels que :\n",
        "    - où se trouvent les données\n",
        "    - où générer les fichiers de vocabulaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmJj2VzPl5p0"
      },
      "source": [
        "Maintenant, nous devons transformer nos textes en une représentation traitable par le modèle, souvent appelée la vectorisation des textes ou la création d'un vocabulaire (en français technique, le plongement lexical). OpenNMT vous offre la fonction *onmt_build_vocab* pour cette tâche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-riq5HkO3Kl"
      },
      "outputs": [],
      "source": [
        "# OpenNMT Construire le vocabulaire \n",
        "\n",
        "!onmt_build_vocab -c $config_name -n_sample -1 --dump_samples # -1 full corpus, bpe, sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyTi9iLvl5p0"
      },
      "outputs": [],
      "source": [
        "!head bam2fr/run/bam2fr.vocab.src.txt\n",
        "!tail bam2fr/run/bam2fr.vocab.src.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe34hfPxQ1qc"
      },
      "source": [
        "La commande `onmt_build_vocab` construit le vocabulaire nécessaire à l'apprentissage. Ici, nous l'avons appelé avec trois paramètres\n",
        "\n",
        "- `-c config_file` : chemin du fichier de configuration à utiliser pour le processus de création de vocabulaire\n",
        "\n",
        "- `-n_sample -1` : la construction d'un vocabulaire à l'aide du corpus complet peut remplacer **-1** par n'importe quel nombre, lorsque l'argument est omis, sa valeur par défaut est 5000.\n",
        "\n",
        "- `-- dump_samples` : (argument facultatif) Écrire des échantillons lors de la construction du vocabulaire, trouvés dans `model_name/run/model_name`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoBPyy7vl5p1"
      },
      "source": [
        "On n'est pas obligé d'utiliser *onmt_build_vocab* pour la construction du vocabulaire, nous pouvons appliquer notre propre algorithme pour arriver à la même fin. Souvent, cela est nécessaire afin d'arriver à des résultats optimaux. Ci-dessous nous remplaçons *onmt_build_vocab* avec une fonction de tokenisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYamw9WKQ1qc"
      },
      "outputs": [],
      "source": [
        "# Custom Tokenization (rm-daba-tokenizer) \n",
        "# - Shown as example, CELL can be skipped\n",
        "\n",
        "from rmai.utils import daba\n",
        "\n",
        "dabautil = daba.DabaUtils()\n",
        "dabautil.tokenize_line(trainbam+validbam)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16UMoYNuQ1qc"
      },
      "source": [
        "[`Daba`](https://github.com/maslinych/daba) est un ensemble logiciel incroyable développé par des linguistes de l'INALCO. Daba est une boîte à outils pour les linguistes, et par conséquent pour nous, les gens des sciences informatiques qui cherchons à travailler avec la langue bambara.\n",
        "\n",
        "- Si vous cherchez à travailler avec Bambara, nous vous le recommandons fortement.\n",
        "\n",
        "\n",
        "Mais, pour la suite de cet atelier, nous allons utiliser le vocabulaire que nous avons créé avec OpenNMT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNxx3TUCQ1qd"
      },
      "source": [
        "## Apprentissage\n",
        "\n",
        "\n",
        "#### Architecture d'un modèle\n",
        "\n",
        "Nous \"concevons\" le modèle à travers la configuration que nous avons générée précédemment. Dans la cellule de code ci-dessous, nous fixons tous les paramètres de notre modèle.\n",
        "\n",
        "*Bien que le fichier de configuration puisse subir de nombreuses modifications afin d'optimiser les résultats,* nous limiterons les changements à quelques options, car nous n'avons pas assez de temps pour discuter tous. Le sujet est vaste.\n",
        "\n",
        "Vous pouvez appeler cette configuration comme ingrédients de la sorcière.\n",
        "\n",
        "- save_model : est le chemin dans lequel le point de contrôle de notre modèle est enregistré.\n",
        "- save_checkpoint_steps : X, à chaque étape X de l'entraînement, un point de contrôle est enregistré.\n",
        "- train_steps : Nombre d'étapes d'entraînement\n",
        "- valid_steps : exécuter la validation, toutes les X étapes\n",
        "- warmup_step : étape permettant d'ajuster le taux d'apprentissage après le début de l'entraînement.\n",
        "- GPU : basculer si vous utilisez GPU ou CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6lqguLW2V7-"
      },
      "outputs": [],
      "source": [
        "training_steps = 500 # 1000 # Number of steps for the training\n",
        "save_freq =  int(training_steps / 2) #100 # Checkpoint saving steps\n",
        "valid_steps = int(training_steps/ 4) # 50 # Steps to validate training perfomance\n",
        "warmup_step = int(training_steps/ 4) #125 # Warmup 1/4th of training total\n",
        "GPU = 0 # 0: CPU or 1:GPU\n",
        "\n",
        "config += f\"\"\"\n",
        "save_model: {model_name}/{model_name}\n",
        "save_checkpoint_steps: {save_freq}\n",
        "keep_checkpoint: 1 # Better for this activity\n",
        "seed: 1234\n",
        "train_steps: {training_steps}\n",
        "valid_steps: {valid_steps}\n",
        "report_every: {valid_steps}\n",
        "warmup_steps: {warmup_step}\n",
        "\"\"\"\n",
        "\n",
        "if(GPU):\n",
        "    config += \"\"\"\n",
        "world_size: 1 # CPU\n",
        "gpu_ranks: [0] # Change to number of GPU if more than 1 GPU\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxjQKUcJrMtC"
      },
      "source": [
        "Bon à savoir : 2-layer LSTM configuration automatique, en bas Il s'agit d'une architecture de modèle de transformateur (transformer).\n",
        "\n",
        "Inspiré de :\n",
        "- [https://github.com/OpenNMT/OpenNMT-py/blob/master/config/config-transformer-base-1GPU.yml](https://github.com/OpenNMT/OpenNMT-py/blob/master/config/config-transformer-base-1GPU.yml)\n",
        "- Travail effectué par [A. A. Tapo](https://github.com/israaar)\n",
        "\n",
        "- **Toggle**: pour transformateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ckWMM28_Cbil"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Transformer Configuration\n",
        "\n",
        "transformer = 0 # Set to 1\n",
        "if (transformer):\n",
        "  config += \"\"\"\n",
        "\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 256\n",
        "valid_batch_size: 64\n",
        "max_generator_batches: 2\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"text\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 1\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 6\n",
        "dec_layers: 6\n",
        "heads: 4\n",
        "hidden_size: 512\n",
        "word_vec_size: 512\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZUmu57El5p2"
      },
      "source": [
        "*Tâche 2* Votre tâche ici est de réécrire le fichier de configuration avec la configuration nouvelle. \n",
        "\n",
        "Astuce : Le fichier est *config_name*, les paramètres nouveaux se trouvent dans la variable *config*, en Python on remplace le contenu d'un fichier avec l'indication *w*.\n",
        "\n",
        "Si votre Python n'est pas encore à l'hauteur, vous trouverez la solution dans la cellule ci-dessous, vous pouvez l'exécuter directement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fckFbeS8l5p3"
      },
      "outputs": [],
      "source": [
        "# CODE ou PSEUDOCODE ICI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0rlimCoQSJuK"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "with open(config_name, \"w\") as fp:\n",
        "    fp.write(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_C_ZPwJQ1qf"
      },
      "source": [
        "- **NOW LET THE MAGIC BEGIN (Place à la magie !)**\n",
        "\n",
        "Nous allons exécuter notre expérience, mais avant de lancer la commande d'apprentissage, nous allons démarrer tensorboard. ***Tensorboard*** nous aide à visualiser ce qui se passe avec notre modèle en entrainement.\n",
        "\n",
        "**Important** : Si vous obtenez une erreur `403`. Activez Cookie / Autorisez le navigateur à afficher le Tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLh7prcWsNMs"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir bam2fr/logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22JivmvFktz-"
      },
      "source": [
        "Le `onmt_train` prend le fichier de configuration comme argument. Espérons que si nous avons tout fait avant, l'entrainenment devrait commencer sans aucun problème. La durée de la formation dépend des étapes de l'entrainement, de la puissance de calcul et de data_size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooPXDOZ8PYYN"
      },
      "outputs": [],
      "source": [
        "!onmt_train -config $config_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOoCm4TOktz-"
      },
      "source": [
        "## Essai & Évaluation des performances [BLEU, Tensorboard]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uothZY8uLiZ"
      },
      "source": [
        "### Tâche 3\n",
        "Vous allez créer vos propres données pour tester la performance du modèle. Il s'agit de préparer les phrases en bambara, étant le texte source ou la question, et de préparer la traduction de chaque phrase en français, étant la bonne réponse. Puis, vous allez soumettre vos textes au modèle et vous allez comparer ce que le modèle donne pour réponse à la bonne réponse qu'un expert (vous) a préparé.\n",
        "\n",
        "- Créer les fichiers de test (les phrases équivalentes dans les deux langues)\n",
        "    - Créez un nouveau fichier avec le nom *mbam.txt* dans le répertoire `data` puis écrivez quelques lignes de bambara dans le fichier.\n",
        "    - Créez un autre fichier nommé *mfr.txt* dans le répertoire `data` puis écrivez les traductions françaises des phrases dans le fichier texte de bambara dans le même ordre.\n",
        "    \n",
        "*Astuce* : Beaucoup de Maliens bambaraphone n'ont pas l'habitude d'écrire le Bambara. C'est triste, mais vrai ! Si c'est votre cas, vous pourriez utiliser Google traduction (https://translate.google.com/?sl=fr&tl=bm&op=translate) pour créer vos phrases en Bambara depuis les phrases que vous écrivez en français.\n",
        "\n",
        "*Astuce 2* : Si votre français n'est pas non plus trop recommandable, vous pouvez copier des phrases de ce notebook à Google traduction.\n",
        "\n",
        "Si vous vous sentez trop paresseux ou sans inspiration pour même copier les phrases, utilisez donc notre kit de test en exécutant la cellule ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "R5-Mdf1zktz_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Test Set\n",
        "bamf = \"https://raw.githubusercontent.com/RobotsMali-AI/rmai/master/mbam.txt\"\n",
        "fraf = \"https://raw.githubusercontent.com/RobotsMali-AI/rmai/master/mfr.txt\"\n",
        "\n",
        "!wget {bamf} {fraf} -P data # Bam-Fra\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW-fthQWktz_"
      },
      "source": [
        "La commande `onmt_translate` est utilisée pour effectuer la traduction avec le modèle formé. En langage de l'apprentissage automatique, l'opération s'appelle *inférence*. Ici, nous utilisons cinq paramètres :\n",
        "- `model` : un fichier de point de contrôle de modèle\n",
        "- `src` : notre fichier de test la langue source\n",
        "- `output` : où nous voulons écrire les prédictions de notre modèle\n",
        "- `gpu` : nombre de GPU sur lesquels exécuter\n",
        "- `verbose` : affiche les scores par prédiction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVmk4Q1DSqBa"
      },
      "outputs": [],
      "source": [
        "ckpt_step = training_steps\n",
        "\n",
        "tsrc = \"mbam.txt\" # Change this to your bambara test file\n",
        "\n",
        "selected_model_name = f\"{model_name}_step_{ckpt_step}.pt\"\n",
        "output = f\"{model_name}/pred_{model_name}_{ckpt_step}.txt\"\n",
        "\n",
        "!onmt_translate -model $model_name/$selected_model_name -src data/$tsrc -output $output # -gpu -1 -verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S6T_PoSstLe"
      },
      "outputs": [],
      "source": [
        "!cat data/$tsrc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctkeXQrJkt0A"
      },
      "source": [
        "**Ta-da! Let's see how our model did, now. Voyons nos résultats. **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYG9zMIYkt0A"
      },
      "outputs": [],
      "source": [
        "!cat $output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w03t08lLkt0A"
      },
      "source": [
        "Le score de Bleu `(BiLingual Evaluation Understudy)` est une mesure automatique pour évaluer la traduction automatique. C'est utile, car cela nous permet d'avoir une idée générale de la façon dont notre modèle fonctionne si nous travaillons avec un modèle plus grand et une taille de données plus grande.\n",
        "\n",
        "Dans notre cas, nous utiliserons notre propre traduction comme référence pour déterminer les performances de notre modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmwFxAjTQ1qh"
      },
      "outputs": [],
      "source": [
        "reference = \"data/mfr.txt\"\n",
        "\n",
        "!sacrebleu $reference -i $output -m bleu -b -w 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L23IDjKGkt0B"
      },
      "source": [
        "Prochaine étape : revenez en arrière et ajustez les paramètres pour votre propre personnalisation.\n",
        "\n",
        ">>> **Merci de nous avoir rejoint. Assistez à l'atelier NLP le samedi pour en savoir plus sur le NLP, et le ASR.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vslfOYyiQ1qh"
      },
      "source": [
        "<div>\n",
        "\n",
        "<img width=\"250\" src=\"https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img/https://indabax.robotsmali.org/wp-content/uploads/2022/11/robotsmali.png\" />\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
